from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()

client = OpenAI(api_key=os.getenv("DEEPSEEK_API_KEY"),base_url=os.getenv("DEEPSEEK_BASE_URL"))

print("\n" + "="*50)
print("ğŸ¤– å¼€å§‹æµå¼æ¨ç†è¿‡ç¨‹")
print("="*50)

response = client.chat.completions.create(
    model="deepseek-r1",
        messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": """ ä½ å¥½ï¼ä¸¤ä¸ªå°æ•° 9.11å’Œ9.8 å“ªä¸€ä¸ªå¤§ï¼Ÿ  """},
    ],
    # 1.å°†æ­¤å¤„çš„Stream æ”¹ä¸º Trueï¼Œè¿™ä¸ºStreamæ¨¡å¼
    stream=True
)

# å®šä¹‰å®Œæ•´æ€è€ƒè¿‡ç¨‹
reasoning_content = ""
# å®šä¹‰å®Œæ•´å›å¤
answer_content = ""

print("\nğŸ’­ æ€è€ƒè¿‡ç¨‹ï¼š")
print("-"*30)

for chunk in response:
    # è·å–æ€è€ƒè¿‡ç¨‹
    reasoning_chunk = chunk.choices[0].delta.reasoning_content
    # è·å–å›å¤
    answer_chunk = chunk.choices[0].delta.content
    # å¦‚æœæ€è€ƒè¿‡ç¨‹ä¸ä¸ºç©ºï¼Œåˆ™æ‰“å°æ€è€ƒè¿‡ç¨‹
    if reasoning_chunk is not None and reasoning_chunk != "":
        print(reasoning_chunk,end="")
        reasoning_content += reasoning_chunk
    # å¦‚æœå›å¤ä¸ä¸ºç©ºï¼Œåˆ™æ‰“å°å›å¤ã€‚å›å¤ä¸€èˆ¬ä¼šåœ¨æ€è€ƒè¿‡ç¨‹ç»“æŸåè¿”å›
    elif answer_chunk is not None and answer_chunk != "":
        print("\n\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆï¼š")
        print("âœ¨"*20)
        print(answer_chunk,end="")
        answer_content += answer_chunk

print("\n\n" + "="*50)
print("ğŸ“ å®Œæ•´è¾“å‡ºï¼š")
print("="*50)
print("\nğŸ¤” æ€è€ƒè¿‡ç¨‹ï¼š")
print("-"*30)
print(reasoning_content)
print("\nğŸ’¡ æœ€ç»ˆç­”æ¡ˆï¼š")
print("-"*30)
print(answer_content)
print("\n" + "="*50)